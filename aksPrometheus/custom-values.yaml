---
kubelet:
  serviceMonitor:
    insecureSkipVerify: true
kubeControllerManager:
  enabled: false
kubeScheduler:
  enabled: false
kubeEtcd:
  enabled: false
kubeProxy:
  enabled: false
alertmanager:
  config:
    receivers:
      - name: 'null'
      - name: 'pagerduty-receiver'
        pagerduty_configs:
          - routing_key: 'dummykey'
            # class: '{{ range .Alerts }}{{ .Labels.alertname }}{{ end }}'
            description: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing| len }}{{ end }}] {{ .CommonAnnotations.summary }}'
            severity: '{{ if .CommonLabels.severity }}{{ .CommonLabels.severity | toLower }}{{ else }}critical{{ end }}'
            # group: '{{ range .Alerts }}{{ .Labels.namespace }}{{ end }}'
            details:
              cluster: 'dummykey'
              environment: 'dummykey'
              firing: '{{ template "pagerduty.default.instances" .Alerts.Firing }}'
              resolved: '{{ template "pagerduty.default.instances" .Alerts.Resolved }}'
              num_firing: '{{ .Alerts.Firing | len }}'
              num_resolved: '{{ .Alerts.Resolved | len }}'
            send_resolved: true
    route:
      group_interval: 30s
      group_by: ['alertname']
      group_wait: 30s
      repeat_interval: 1m
      receiver: 'null'
      routes:
        - receiver: 'null'
          match:
            alertname: Watchdog
        - receiver: 'null'
          match:
            alertname: InfoInhibitor
        - receiver: 'null'
          match:
            alertname: TargetDown
            job: 'monitoring/flink-metrics-monitor'
        - receiver: 'pagerduty-receiver'
grafana:
  enabled: false
prometheus:
  prometheusSpec:
    retention: "defaultretention"
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: "defaultstorage"
    additionalPrometheusRules: |
      # Override the CPUThrottlingHigh alert with a 90% threshold
      - alert: CPUThrottlingHigh
        expr: sum by (container, pod, namespace) (increase(container_cpu_cfs_throttled_periods_total{container!=""}[5m])) / sum by (container, pod, namespace) (increase(container_cpu_cfs_periods_total[5m])) > (90 / 100)  # Set to 90% threshold
        for: 15m
        labels:
          severity: critical
        annotations:
          description: "{{ $value | humanizePercentage }} throttling of CPU in namespace {{ $labels.namespace }} for container {{ $labels.container }} in pod {{ $labels.pod }}."
          runbook_url: "https://runbooks.prometheus-operator.dev/runbooks/kubernetes/cputhrottlinghigh"
          summary: "Processes experience elevated CPU throttling."
                
    containers:
    - name: prometheus
      startupProbe:
        initialDelaySeconds: 60
      readinessProbe:
        initialDelaySeconds: 60 
      livenessProbe:
        initialDelaySeconds: 60 
      resources: 
        requests:
          memory: "defaultmemory" 
    podMetadata:
      annotations:
        owner: "puverma"
        team: "CloudOps"                         
    additionalScrapeConfigs:
      - job_name: kubecost
        honor_labels: true     
        scrape_interval: 1m
        scrape_timeout: 10s
        metrics_path: /metrics
        scheme: http
        dns_sd_configs:      
        - names:        
          - kubecost-cost-analyzer.kubecost.svc
          type: 'A'        
          port: 9003
          
      - job_name: opencost
        honor_labels: true
        scrape_interval: 1m
        scrape_timeout: 10s
        metrics_path: /metrics
        scheme: http
        static_configs:
        - targets: ['opencost.opencost:9003']         

      - job_name: "blackbox-kubernetes-pods"
        metrics_path: /probe
        params:
          module: [http_2xx]
        kubernetes_sd_configs:
        - role: pod
          namespaces:
            names: []
        relabel_configs:
          - source_labels: [__address__]
            target_label: __param_target
          - target_label: __address__
            replacement: blackbox-exporter-prometheus-blackbox-exporter.monitoring.svc.cluster.local:9115  
          - source_labels: [__param_target]
            replacement: ${1}/health  
            target_label: instance
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)  
          - source_labels: [__meta_kubernetes_namespace]
            target_label: kubernetes_namespace  
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: kubernetes_pod_name
     
      - job_name: "blackbox-kubernetes-services"
        metrics_path: /probe
        params:
          module: [http_2xx]
        kubernetes_sd_configs:
        - role: service
        relabel_configs:
          - source_labels: [__address__]
            target_label: __param_target
          - target_label: __address__
            replacement:  blackbox-exporter-prometheus-blackbox-exporter.monitoring.svc.cluster.local:9115
          - source_labels: [__param_target]
            target_label: instance
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_service_name]
            target_label: kubernetes_service_name
      - job_name: "blackbox-kubernetes-ingresses"
        metrics_path: /probe
        params:
          module: [http_2xx]
        kubernetes_sd_configs:
        - role: ingress
        relabel_configs:
          - source_labels:
              [
                __meta_kubernetes_ingress_scheme,
                __address__,
                __meta_kubernetes_ingress_path,
              ]
            regex: (.+);(.+);(.+)
            replacement: ${1}://${2}${3}
            target_label: __param_target
          - target_label: __address__
            replacement: blackbox-exporter-prometheus-blackbox-exporter.monitoring.svc.cluster.local:9115
          - source_labels: [__param_target]
            target_label: instance
          - action: labelmap
            regex: __meta_kubernetes_ingress_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_ingress_name]
            target_label: ingress_name
            
      - job_name: prometheus-blackbox-exporter
        metrics_path: /probe
        params:
          module: [http_2xx]  
        static_configs:
          - targets:
            - "https://hq.detroitconnect.com" 
        relabel_configs:
          - source_labels: [__address__]
            target_label: __param_target
          - target_label: __address__
            replacement: blackbox-exporter-prometheus-blackbox-exporter.monitoring.svc.cluster.local:9115  
          - source_labels: [__param_target]
            replacement: ${1}/health
            target_label: instance
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: kubernetes_pod_name

    serviceMonitorSelector:
      matchLabels:
        release: "prometheus"
      